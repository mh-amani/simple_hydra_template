# @package _global_

# specify here default configuration
# order of defaults determines the order in which configs override each other
defaults:
  - _self_
  - data: parity
  - model: llama
  # experiment configs allow for version control of specific hyperparameters
  # e.g. best hyperparameters for given model and datamodule
  - experiment: null


trainer:
  _target_: lightning.pytorch.trainer.Trainer

  default_root_dir: ${paths.output_dir}

  min_epochs: 1 # prevents early stopping
  max_epochs: 10

  accelerator: gpu
  devices: 1

  # mixed precision for extra speed-up
  # precision: 16

  # perform a validation loop every N training epochs
  check_val_every_n_epoch: 1
  log_every_n_steps: 1

  # set True to to ensure deterministic results
  # makes training slower but gives more reproducibility than just setting seeds
  deterministic: False
  logger: 
    _target_: lightning.pytorch.loggers.WandbLogger


paths:
  # path to root directory
  # this requires PROJECT_ROOT environment variable to exist
  # you can replace it with "." if you want the root to be the current working directory
  root_dir: ${oc.env:PROJECT_ROOT}
  # path to data directory
  data_dir: ${paths.root_dir}/data/
  # path to logging directory
  log_dir: ${paths.root_dir}/logs/
  # path to output directory, created dynamically by hydra
  # path generation pattern is specified in `configs/hydra/default.yaml`
  # use it to store all files generated during the run, like ckpts and metrics
  output_dir: ${hydra:runtime.output_dir}
  # path to working directory
  work_dir: ${hydra:runtime.cwd}

# task name, determines output directory path
task_name: "finetune_gpt2_on_stupid_dataset"

hydra: # https://hydra.cc/docs/configure_hydra/intro/
  # enable color logging
  defaults:
    - override hydra_logging: colorlog
    - override job_logging: colorlog

  # output directory, generated dynamically on each run
  run:
    dir: ${paths.log_dir}/${task_name}/runs/${now:%Y-%m-%d}_${now:%H-%M-%S}
  sweep:
    dir: ${paths.log_dir}/${task_name}/multiruns/${now:%Y-%m-%d}_${now:%H-%M-%S}
    subdir: ${hydra.job.num}

  job_logging:
    handlers:
      file:
        # Incorporates fix from https://github.com/facebookresearch/hydra/pull/2242
        filename: ${hydra.runtime.output_dir}/${task_name}.log

# seed for random number generators in pytorch, numpy and python.random
seed: 42